{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the Necessary Libraries and Define Some Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFilter, ImageEnhance\n",
    "import imagehash\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/Cellar/tesseract/5.2.0/bin/tesseract'\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from natsort import natsorted\n",
    "\n",
    "#simple function to pickle variables for later use. save a local pickle\n",
    "def save_object(obj, filename):\n",
    "    '''Help: Given an object & filepath, store the object as a pickle for later use.'''\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"File saved at {filename}\")\n",
    "\n",
    "#and later load the file back into a variable\n",
    "def load_object(filename):\n",
    "    '''Help: Loads something previously pickled from the provided file path.'''\n",
    "    with open(filename, 'rb') as f:\n",
    "        load_test = pickle.load(f)\n",
    "    print(f\"File loaded from {filename}\")\n",
    "    return load_test\n",
    "\n",
    "def find_potential_card_matches(parsed_title, verbose=False):\n",
    "    '''Help: Given a string of \"words\" in the card title from the OCR, find all printings that \n",
    "    could possibly match. Filter out invalid words from the OCR parsed text, and find all of the\n",
    "    valid MTG cards that contain the parsed words. Find all printings of the matching card names\n",
    "    and store them in a dataframe along with relevant info & urls. Printings for which no digital\n",
    "    image is available are exlcuded. Returns Pandas dataframe with all potential matches.'''\n",
    "    \n",
    "    #after the OCR processing, we need to gather a large list of cards that could match\n",
    "\n",
    "    #first determine which of the parsed OCR words are valid, and keep only those\n",
    "    valid_cardname_words = [word for word in parsed_title if word in unique_cardname_words]\n",
    "    \n",
    "    #also filter out single letter words to cut down on potential options\n",
    "    valid_cardname_words = [word for word in valid_cardname_words if len(word)>1]\n",
    "\n",
    "    if verbose:\n",
    "        print(f'OCR Result:{parsed_title} filtered to {valid_cardname_words}\\n')\n",
    "\n",
    "    #now find any magic card names that include any of the MTG valid parsed text\n",
    "    potential_matches = []\n",
    "    for keyword in valid_cardname_words:\n",
    "        potential_matches.extend([card_match for card_match in valid_card_names if \n",
    "                                  keyword in card_match.split()])\n",
    "\n",
    "    #remove duplicate card names that were found\n",
    "    potential_matches = set(potential_matches)\n",
    "    if verbose:\n",
    "        print(f'Potential Matches: {potential_matches}')\n",
    "    \n",
    "    #initialize a new dataframe to store this subset of cards\n",
    "    potential_matches_df = pd.DataFrame(columns=card_database.columns)\n",
    "\n",
    "    #for each potential card name, find and store all printings\n",
    "    for potential_match in potential_matches:\n",
    "        #get all card entries matching the card name\n",
    "        initial_subset = card_database.loc[(card_database['name']==potential_match)]\n",
    "        #find entries without a link to the card image\n",
    "        no_img_entries = initial_subset[initial_subset['image_url'].isna()].index\n",
    "        #remove entries without an available card image\n",
    "        subset_with_imgs =  initial_subset.drop(no_img_entries)\n",
    "\n",
    "        #add the potential matches to the new database\n",
    "        potential_matches_df = potential_matches_df.append(subset_with_imgs)\n",
    "        \n",
    "    #also drop any duplicate entries\n",
    "    potential_matches_df = potential_matches_df.drop_duplicates()\n",
    "        \n",
    "    return potential_matches_df\n",
    "        \n",
    "def initial_card_scan(local_img, verbose=False):\n",
    "    '''Help: Given a PIL image, crop and use tesseract OCR to quickly read the title area on the card.\n",
    "    Returns parsed text that includes all \"characters\" recognized by the OCR, even wrong ones!'''\n",
    "\n",
    "    #crop the sample image to just the area where card title typically is written, subject to camera\n",
    "    crop_portion = 0.15\n",
    "\n",
    "    #create a cropped version of the starting image\n",
    "    local_img_title = local_img.crop((0,0,local_img.size[0], local_img.size[1]*crop_portion))\n",
    "\n",
    "    #resize so that each image is 1000px wide, maintaining aspect ratio\n",
    "    basewidth = 1000\n",
    "    wpercent = (basewidth/float(local_img_title.size[0]))\n",
    "    hsize = int((float(local_img_title.size[1])*float(wpercent)))\n",
    "    local_img_title = local_img_title.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "    \n",
    "    #use tesseract OCR to read the title\n",
    "    parsed_title = pytesseract.image_to_string(local_img_title).split()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Parsed Characters: {parsed_title}')\n",
    "        \n",
    "    return parsed_title, local_img_title\n",
    "\n",
    "def card_match_scan(local_img, potential_matches_df, verbose=False):\n",
    "    '''Help: Given the local_img card & the dataframe of potential matches, determine with reasonable\n",
    "    confidence the multiverse_id of the local card.'''\n",
    "    \n",
    "    #hash the orginal local image\n",
    "    local_img_hash = imagehash.average_hash(local_img)\n",
    "    \n",
    "    #create an array to store the comparison results\n",
    "    hash_results = np.empty(shape=(0), dtype=int)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Local image hash generated...')\n",
    "    \n",
    "    #for each potential match, has the card image and compare to the local image\n",
    "    for index, potential_match in potential_matches_df.iterrows():\n",
    "        #get the multiverse ID of the potential match\n",
    "        multiverse_id = potential_match['multiverse_id']\n",
    "\n",
    "        #get the image url and pull the image file\n",
    "        img_url = potential_match['image_url']\n",
    "        ref_img = Image.open(urlopen(img_url))\n",
    "                \n",
    "        #compare this ref_image to the live_img captured locally\n",
    "        ref_img_hash = imagehash.average_hash(ref_img)\n",
    "\n",
    "        #calculate the similarity between the photo hashes\n",
    "        hash_similarity = local_img_hash - ref_img_hash\n",
    "\n",
    "        hash_results = np.append(hash_results,hash_similarity)\n",
    "        #print(f'Card {multiverse_id} scored {hash_similarity}')\n",
    "        \n",
    "        if verbose:\n",
    "                print(f'{multiverse_id} opened & hashed with a score of {hash_similarity} ...')\n",
    "                \n",
    "    #add the hash_results to the original dataframe\n",
    "    potential_matches_df['hash_results'] = hash_results\n",
    "\n",
    "    #sort the dataframe in likeliness of card match, and grab the top 15 most likely hash results\n",
    "    initial_matches = potential_matches_df.sort_values('hash_results').iloc[:15]\n",
    "\n",
    "    return initial_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our prepared Database & Cardname List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load the packaged card data\n",
    "card_database = load_object('card_database.p')\n",
    "unique_cardname_words = load_object('unique_cardname_words.p')\n",
    "valid_card_names = load_object('valid_card_names.p')\n",
    "#and create the necessary folder structure\n",
    "os.mkdir('Demo Images')\n",
    "os.mkdir('Processed OCR Input Images')\n",
    "os.mkdir('Raw OCR Input Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a sample set of common cards & images to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#find all entries with an image that match a given card name\n",
    "\n",
    "card_name = 'Llanowar Elves'       #'Giant Growth', 'Cancel', 'Llanowar Elves' etc..\n",
    "\n",
    "#pull all matching cards\n",
    "all_matches = card_database[card_database['name'] == card_name]\n",
    "\n",
    "#remove entries without an available image url\n",
    "no_img_entries = all_matches[all_matches['image_url'].isna()].index\n",
    "result =  all_matches.drop(no_img_entries)\n",
    "\n",
    "#print the result\n",
    "print(f\"{len(result)} printings of {card_name} found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now pull & save each image file for demo use\n",
    "for multiverse_id in list(result['multiverse_id']):\n",
    "    card = result[result['multiverse_id']==multiverse_id]\n",
    "    #load the image file from the internet\n",
    "    image_file = Image.open(urlopen(card['image_url'].item()))\n",
    "    #save a copy locally with the multiverse_id as the filename\n",
    "    image_file.save(f'Demo Images/{multiverse_id}.png')\n",
    "    #print a brief message about the results\n",
    "    print(f\"{card['name'].item()} from {card['set_name'].item()} \\\n",
    "saved as {multiverse_id}.png ({image_file.size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run each card through the OCR and see what comes back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pull each card image saved locally, edit contrast & brightness, then crop to typical title area\n",
    "for card in natsorted(os.listdir('Demo Images')):\n",
    "    if card.endswith('.png'):\n",
    "        #open the image file\n",
    "        img = Image.open(f'Demo Images/{card}')\n",
    "        #use tesseract OCR to scan it\n",
    "        ocr_result, scanned_img = initial_card_scan(img, False)\n",
    "        #save for reference the image that was scanned\n",
    "        scanned_img.save(f'Raw OCR Input Images/{card}')\n",
    "        \n",
    "        print(f\"{card} raw OCR scan found: {ocr_result}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the cards then run them through the OCR scanner again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pull each card image saved locally, edit contrast & brightness, then crop to typical title area\n",
    "for card in natsorted(os.listdir('Demo Images')):\n",
    "    if card.endswith('.png'):\n",
    "        img = Image.open(f'Demo Images/{card}')\n",
    "        #increase the image brightness\n",
    "        converter = ImageEnhance.Brightness(img)\n",
    "        img = converter.enhance(1.25)\n",
    "        #increase the image contrast\n",
    "        converter = ImageEnhance.Contrast(img)\n",
    "        img = converter.enhance(1.25)\n",
    "        #run the card through the OCR scan again\n",
    "        ocr_result, scanned_img = initial_card_scan(img, False)\n",
    "\n",
    "        #save for reference the image that was scanned\n",
    "        scanned_img.save(f'Processed OCR Input Images/{card}')\n",
    "        \n",
    "        print(f\"{card} raw OCR scan found: {ocr_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take the best case OCR result and find all close MTG cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take any of the above results that look decent\n",
    "ocr_result, current_multiverse_id = , \n",
    "\n",
    "#determine all possible MTG cards that could be a match\n",
    "potential_matches_df = find_potential_card_matches(ocr_result)\n",
    "potential_matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the set of close card matches, use imagehashing to find closest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#first reload the image that we have chosen\n",
    "local_img = Image.open(f\"Demo Images/{current_multiverse_id}.png\")\n",
    "\n",
    "#use imagehashing to scan all relevant cards and return closest matches\n",
    "hashing_results = card_match_scan(local_img, potential_matches_df, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once done, store the results sorted by hash similarity\n",
    "hashed_matches = potential_matches_df.sort_values('hash_results').iloc[:15]\n",
    "\n",
    "#and print the top 15 results\n",
    "print(hashed_matches[['multiverse_id','image_url','hash_results']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks for watching! Stay tuned for a better method to actually do this!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
